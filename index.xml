<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sphinxxx1984 Blog</title>
    <link>https://sphinxxx1984.github.io/</link>
    <description>Recent content on Sphinxxx1984 Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ch-Hans</language>
    <copyright>©2020, Xinyu Ye. All rights reserved.</copyright>
    <lastBuildDate>Mon, 14 Sep 2020 07:44:00 +0800</lastBuildDate>
    
	<atom:link href="https://sphinxxx1984.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>邮件自动分类与数据挖掘</title>
      <link>https://sphinxxx1984.github.io/slides/text_mining/</link>
      <pubDate>Mon, 14 Sep 2020 07:44:00 +0800</pubDate>
      
      <guid>https://sphinxxx1984.github.io/slides/text_mining/</guid>
      <description>PART ONE 背景分析 邮件分类问题属于文本类的数据挖掘。所谓文本分类，是指对所给出的文本，给出预定义的一个或多个类别标号，对文本进行准确、高效的分类。在本任务中，文本的类别有20种。
一般来说，传统的文本分类过程由以下几个步骤组成：数据预处理、文本特征选择、特征降维、训练分类器和分类性能评估。
 PART TWO 实现思路 STEP1 数据预处理 STEP2 文本特征提取 我们计算单词TF-IDF值的方式来表示一个邮件的文本特征。 而在计算文本TF和IDF的过程中，同时对数据进行处理，筛掉一部分不需要的单词。
共使用了5个job来实现，分别是：
1.计算单词的TF值
2.计算单词的IDF值
3.计算单词的TF-IDF值并生成稀疏向量（&amp;lt;单词索引 单词TF-IDF值&amp;gt;）
4.输出IDF表中的单词和索引（用于查找配对）
5.将3中的稀疏向量的TF-IDF值替换为1并输出（用于朴素贝叶斯）
定义了一个数据结构KeyWord用来记录文件名，文件夹名（类别标记），单词。
 1.TfJob 计算单词的TF值 输入：停词表 数据集
输出：filename,word,dictName TF
Mapper
在setup中加载停词表（通过addCacheFile的方式加载）
Map过程如下：
(1) 去除掉分隔符
(2) 通过StandardAnalyzer分词器进行分词
(3) 将分好的单词再次筛选，去除单个字母和带数字的单词
(4) 每个KeyWord词频为1，输出
在cleanup中输出&amp;lt;__wordNum__, 单词总数&amp;gt;
 1.TfJob 计算单词的TF值 Combiner
(1) 将Mapper中输出的&amp;lt;KeyWord, 1&amp;gt;进行求和
(2) 输出&amp;lt;KeyWord, 总次数&amp;gt;
Reducer
文档可能超过split尺寸大小，被拆分在多个split被多个Map统计单词数。
Reduce过程如下：
(1) 对各个Map统计的单词总数进行汇总
(2) 使用公式计算单词的TF值，按格式输出
 2.IdfJob 计算单词的IDF值 输入：job1的结果
输出：word IDF
通过上一个job的输出统计每个单词出现的文档数
通过hadoop.hdfs的API获得输入文档的总数
从而利用公式计算IDF
 2.</description>
    </item>
    
    <item>
      <title>一些经典机器学习分类算法的介绍</title>
      <link>https://sphinxxx1984.github.io/blog/some_ml_algorithms/</link>
      <pubDate>Tue, 08 Sep 2020 07:35:00 +0800</pubDate>
      
      <guid>https://sphinxxx1984.github.io/blog/some_ml_algorithms/</guid>
      <description>Introduction 分类是什么，怎么样分类呢？分类是什么意思出自哪里？为什么一瞬间就有好多人进行分类？为什么大家都在分类？相信不少同学都想了解这个操作，下面就让小编来为大家介绍一下怎么推导经典的分类算法的详细内容。
1 J4.8(C4.5) 决策树(dicision tree)是一种常见的机器学习方法。以二分类任务为例，我们希望从给定训练数据集学得一个模型用以对新示例进行分类，这个把样本分类的任务，可看作对“当前样本属于正类吗？”这个问题的“决策”或“判定”过程。
顾名思义，决策树是基于树结构来进行决策的。决策过程中提出的每个判定问题都是对某个属性的“测试”，每个测试的结果或是导出最终结论，或是导出进一步的判定问题，其考虑范围是在上次决策结果的限定范围之内。决策过程的最终结论对应了我们所希望的判定结果。
一般地，一棵决策树包含一个根结点、若干个内部结点和若干个叶结点；叶结点对应于决策结果，其他每个结点则对应于一个属性测试；每个结点包含的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。
决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的分治策略：自根至叶的一个递归过程，在每个中间结点寻找一个“划分”(split or test)属性。决策树的学习有3种停止条件：当前结点包含的样本全属于同一类别，无需划分；当前属性集为空，或是所有样本在所有属性上取值相同，无法划分；当前结点包含的样本集合为空，不能划分。
在ID3算法中，使用信息增益(information gain)来选择最优划分属性。 计算公式为: $$\text{Ent}(D) = - \sum_{k = 1}^{|y|}p_{k}\log_{2}p_{k}(if\ p_k = 0,\ p_{k}\log_{2}p_{k} = 0) \ \ (1.1)$$ $$\text{Gain}(D, a) = \text{Ent}(D) - \sum_{v = 1}^{V}\frac{|D^v|}{|D|}\text{Ent}(D^v) \ \ (1.2)$$ ID3算法在实际应用中存在问题：对于可取值数目较多的属性有偏好。Quinlan又在1993年提出了改进版本C4.5算法，使用增益率(gain ratio)来选择最优划分属性。 计算公式为: $$\text{IV}(a) = - \sum_{v = 1}^{V}\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|} \ \ (1.3)$$
$$\text{Gain_ratio}(D, a) = \frac{\text{Gain}(D, a)}{\text{IV}(a)} \ \ (1.4)$$其中IV(a)称为属性a的“固有值”(intrinsic value)。属性a的可能取值数目越多（即V越大），则IV(a)的值通常会越大。 需要注意的是，增益率准则对可取值数目较少的属性有所偏好，因此，C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。
此外，C4.5算法还在以下几方面对ID3算法有所改进：预剪枝处理、连续值处理（二分法）、缺失值处理。
C4.5算法产生的分类规则容易理解且准确率较高。但是，在构造决策树的过程中，C4.5算法需要对数据集进行多次的顺序扫描和排序，导致算法的效率比较低下。当数据集的大小超过内存时。C4.5算法是无法运行的。
C4.5在Weka中的实现为J4.8。
2 Naïve Bayes 贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方法。对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别表及。下面以多分类任务为例解释其基本原理。</description>
    </item>
    
    <item>
      <title>第一篇文章</title>
      <link>https://sphinxxx1984.github.io/blog/first_post/</link>
      <pubDate>Tue, 08 Sep 2020 01:21:00 +0800</pubDate>
      
      <guid>https://sphinxxx1984.github.io/blog/first_post/</guid>
      <description>写在开博客之前 大概在2年半前的一个冬夜，我开了个人的微信公众号，以非常不稳定的频率更新了一年半，内容主要是音乐、个人随笔与咖啡知识。
从去年八月到现在，我都没有在个人的公众号上更新文章，大致原因有二，第一是现实生活过于充实、忙碌，没有闲工夫写东西。第二是深感国内互联网舆论环境之差，一度丧失了表达的欲望。
到2020年的9月，我终于闲了下来，可以安下心地在电脑前码字，分享个人的心得与一些想法。
本博客的用途 本博客和本人的公众号大致形成一种互补的关系，但也不排除交叉的可能性。公众号可能更加偏向非技术的内容一些，博客可能偏向技术性的内容一些。
本人的联系方式 QQ：365248110
手机：15950926782
微信：同手机号
微信公众号：Sphinxxx
微博：CoDe_BlooD
Twitter：@sphinxxx1984
PS：加好友时请备注姓名</description>
    </item>
    
    <item>
      <title>友情链接</title>
      <link>https://sphinxxx1984.github.io/friends/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sphinxxx1984.github.io/friends/</guid>
      <description>doowzs(Tianyun Zhang)
Forewing(Nairong Xie)
Sciroccogti(Yifan Zhang)
Fermat(Zangwei Zheng)</description>
    </item>
    
  </channel>
</rss>